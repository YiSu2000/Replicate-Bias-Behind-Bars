---
title: "Replicate 'Bias Behind Bars' under Bayesian setting"
subtitle: "Logistic regression on risk scores of prison inmates under Bayesian setting"
author: "Su"
thanks: "Code and data are available at: LINK."
date: "`r format(Sys.time(), '%d %B %Y')`"
abstract: |
  | Racial discrimination against the First Nations has been a problem in Canada since the first colonist step on the sides of St. Lawrence river. While this problem has been a controversial among the general public, is it still the possible case in the scope of prison systems? The Globe and Mail investigation indicates that Black and Indigenous prisoners experience worse assessment scores solely base on their race. In this report, we focus on replicating the results of the Globe's investigation under Bayesian settings ,instead of the original Frequentist settings, using the same dataset from Correctional Service of Canada.
  | **keywords:** Logistic Regression, Bias, Racial Discrimination, Correctional Service of Canada, The Globe and Mail
output:
  bookdown::pdf_document2:
toc: FALSE
bibliography: references.bib
header-includes:
 \usepackage{float}
---

```{r setup, include=FALSE, echo = FALSE, message = FALSE, warning=FALSE}
library(knitr)
library(broom)
library(skimr)
library(naniar)
library(tidyverse)
library(haven)
library(tidybayes)
library(ggplot2)
library(brms)
library(statebins)
library(kableExtra)
library(data.table)
library(scales)
RAW <- read_csv("/Users/jordans2000/Desktop/STA304/Replicate-Bias-Behind-Bars/inputs/The_Globe_and_Mail_CSC_OMS_2012-2018_20201022235635/The_Globe_and_Mail_CSC_OMS_2012-2018_20201022235635.csv")
```

# Introduction

For majority of the general public, the part of the world behind bars is likely to be one of the least favorable place to be. Not only because that prisons have a less favorable physical environment, but also because it is filled by heinous criminals. This is, to some extent, a known fact. However, are the prisoners really all that heinous? The answer would be no. Although they all did commit severe crime to be put in the prison, but it does not necessary mean they are all heinous since the severity of their crime are all different. In the prison system, there are various scores, designed by the Correctional Service of Canada (CSC), assessing a criminal's potential threat to inmates of the prison, and also the potential ability to reintegrate to the society after their sentence. These scores are crucial to the inmates since these determines the overall correctional plan and will affect the inmates' life after sentence.

In general, these scores are risk assessments, assessing an inmate's future risk to public using all past and present information for design of a correctional plan. The problem arises from these scores, while these measures are crucial to a prisoner's in-prison life and out-prison life, these are not all determined under a standardized and objective measure, thus bias naturally exist when subjectivity enter. Some of these are measured purely by standardized tests and objective data, but some are purely based on officer's judgment. In case of bias due to subjectivity, it is natural to consider some of the long-lasted bias among the general public like race and gender bias. Racial discrimination against the First Nations have been a problem in North America even before Canada exist as a country, and it would not be surprise if some degree of discrimination exist among prison systems. The Globe and Mail investigation [@citebias] identified that there is bias against Black and First Nations (indigenous) inmates among the assessments. The focus of this report is to replicate the Globe's findings using a Bayesian setting instead of the original Frequentist setting, and examine if the findings still hold statistically. We replicate exactly the original procedure using the same dataset originally obtained from CSC [@citecsc]. However, instead of replicating all three logistic models, we only replicate the first two model analyzing the impact of race on security and reintegration scores.

The article introducing the original methodology [@citemethod] is not a detailed instruction paper and there are many hidden details to the exact methodology. When encountering such an issue, we proceed using our interpretation to the context of the procedure. The final result is slightly different with the article due to these issues, as well as the use of the Bayesian settings. However, the result should agree with the article that there are some bias against Black and Indigenous inmates on CSC assessment scores. We will discuss more detail on the hidden detail interpretation issues in the sections that encounters it. This reports validates the reproducibility on the first two statistical models discussed in "Bias Behind Bars" 

In order to replicate the result of the Globe [@citemethod], we focus on two of the assessment scores, the offender security level and reintegration level, for having the largest impact on an inmate's life behind the bars. Both of these scores are assessed by the CSC officers using a series of specialized tests and interviews, which are all assigned when the inmates first arrive at the federal prison. The offender security level is a set of measure from minimum, medium, to maximum, and maximum bring the 'worst' score. Each inmate with following measure will be assigned to facility or area suiting their security level, for example, an inmate with maximum score will be assigned to area with maximum security level. The reintegration score estimates an inmate's potential to re-enter the society without committing a new offend, and this score is also crucial for the parole hearings. The reintegration is designed to have low, medium, and high levels, assigned using a set of actuarial and non-actuarial assessments, and low bring the 'worst' score. More detailed discussion of the scores is included in *Section 2.1 & 2.2*. 

For the remaining part of the report, *Section 2* includes discussion on the CSC dataset, and some exploratory data analysis for deeper understanding of the dataset. The specific procedure of the investigation by the Globe and the logistic models used are included in *Section 3*. The model results and comparisons to the original results are included in *Section 4*. Lastly, we make discuss about some potential future improvements of the procedure, and draw conclusion base on the comparison results in *Section 5*.

# The CSC 2012-2018 Data 

```{r data cleaning, echo = FALSE, message = FALSE}
#skim(RAW)
RAW <- RAW%>%filter(JURISDICTION == "FEDERAL")
RAW <- RAW%>%drop_na(RACE, `OFFENDER SECURITY LEVEL`, 
                     `STATIC/RISK`, `REINTEGRATION POTENTIAL`)
#filtering all provincial jurisdictions gives us 741829 rows instead of the 741738 rows in the article. We left with 686540 rows after removing all NAs in variables that we need.

RAW$RACE[RAW$`RACE GROUPING`=="Indigenous"] <- "Indigenous"
#set the race to indigenous if their race is classified as indigenous

RAW$RACE <- ifelse(RAW$RACE %in% c("White", "Black", "Indigenous"), RAW$RACE, "Other")
#set all race other than white, black, and indigenous into "other"

#although not said by the author, I recognize a significant amount of rows that have the same fiscal year id and offender id, what changes is the sentence, and everything else remains constant. This due to multiple offences and the system had to put multiple entries in to accommodate that, we make the assumption that an offender only gets a true record of scores each year.
#so we remove all observations that are identical in all variable we test for other than offence id.
RAW <- RAW[!duplicated(RAW[c("FISCAL YEAR", "SENTENCE ID", 
                             "OFFENDER NUMBER", "RACE", "GENDER",
                             "OFFENDER SECURITY LEVEL", "REINTEGRATION POTENTIAL", 
                             "AGE", "STATIC/RISK", "SENTENCE TYPE")]),]
#this reduced our sample size significantly, which is why the subset of model data have such a small sample size compare to the original full dataset.
```

The dataset we use is a Correctional Service of Canada (CSC) dataset from their inmate's database, and this dataset was requested through several levels of bureaucracy (including consent from head of CSC) by Tom Cordoso, the author of "Bias Behind Bars" [@citebias]. The dataset records inmate entries from 2012 to 2018, and for that reason, it can be considered as a panel dataset. It is free of all personal information, containing 744958 entries from 50116 inmates and 25 variables in total (technically it contains 26, but the "judge" variable was set all blank by CSC). Specifically, each year's data given by the CSC is a snapshot of their full database on March 31 of the corresponding year. March 31 is the end of CSC's fiscal year, and for that reason, the unit of year in this dataset is fiscal year like YE1112 means the fiscal year 2011-2012, instead of the "common" year unit like 2015. 

Table \@ref(tab:tab1) displays an example of observations in the CSC dataset, restricting to variables we discuss and use in the context of "Bias Behind Bars" [@citebias]. All Tables (excluding model results) in this report was made in `R` [@citeR], using `kable` package [@citekable] and the extension of it `kableExtra` [@citeextras].

The variables recorded include the offender security score and reintegration potential score, which are the two response variables we are interested in. As well as the characteristic that should be controlled to achieve less biased results, including age, gender, year recorded, sentence type, and static score. The sentence types are separated into determinate and indeterminate (life sentence), indicating severity of crime to some degree. The static score corresponds to the risk level of the offender, it is assigned using Static Factors Assessment, a CSC tool measuring the inmates’s past involvement with the criminal justice system (some are crime records). Thus, a higher static score means the inmate has had a decent record with the criminal justice system in the past, and thus indicates an inmate's crime history to some extent. Fiscal years and offence ID appear in CSC coding format, which are not unique to each inmate, but to that specific year or offence type. Meanwhile, offender ID and sentence ID are individual specific for every sentence the offender attempted between 2012-2018 fiscal years.

```{r tab1, echo = FALSE, message = FALSE}
options(knitr.kable.NA = '')
#use knitr to convert NAs into empty strings
kable(RAW[c(1,11,1111,22111),c(1,2,3,4,6,7,10,11,16,18,19,25)], 
      #example rows including variables we are interested in
      col.names = c("Fiscal Year", "Sentence ID", "Offender Number", "RACE", "Gender","Age", "Jurisdiction", "Sentence Type", "Offender Security Level", "Static", "REintegration Potential", "Offence ID"),
      align = "c", 
      caption = "Sample Observations")%>%
  kable_styling(latex_options = c("HOLD_position","scale_down"))
#fix position of the table
```

The article also generated numerical offence severity, by hand-matching over 700 offence types recorded in this dataset with the Uniform Crime Reporting Survey's offence category codes (product of Statistics Canada). In that way, the new offence codes can be matched with Statistics Canada's weighting system for Crime Severity Index (CSI), which represents a numerical measure of severity of the offence. However, this procedure of hand-matching over 700 offence types is not very realistic given the time constraints of this report especially when it was available later in the time line. Nevertheless, we still thank Rohan Alexander for gathering the complete 2018 CSI weight document from Tom Cordoso (it is a public document, but is not open for download on Statistics Canada ). This action will cause our replicate model to have one less control variable to include, which is the most sever offence of an inmate. The resultant issues will be discussed in *Section 5*.

For the remaining of the report, we perform data manipulation, result visualization, and statistical model training in `R` [@citeR]. In the data manipulation steps, the packages `tidyr` [@citetidyr], `tidyverse` [@citetidyverse], `skimr` [@citeskimr], and `naniar` [@citenaniar] were used. The replication of data cleaning begins with removing all entries for inmates on provincial jurisdiction. This step was not an explicitly step written in the methodology instruction, it was included in a bracket, and we assume it is a necessary step to take. However, we already come to a difference with the article results in the first step, the author mentioned he had 741,738 entries after removing the provincial jurisdictions, but our result showed 741829 entries without missing value in jurisdictions. Fortunately this is not a major concern, but it rings the bell that differences should be expected in most further steps.

Next, we implement our usual steps when dealing with raw data. We removed the missing values in the variables we are interested in (three sores, age, gender, year, sentence type). This reduce the dataset size to 686540 entries. For the 34 race categories in the dataset, we replicate the article methodology of classifying Indigenous races to "Indigenous" race category, and classify all races other than White, Black, and Indigenous, into "other" race category. This classification allows the model to focus on differences between White, Black, and Indigenous groups. The Indigenous classification reference we used in directly from the race grouping categories in the CSC dataset, while the article used Ontario’s Data Standards for the Identification and Monitoring of Systemic Racism, which is a guide for identifying racial disparities in data. Assuming the CSC follows a similar, and ethic classification system, we should not encounter major differences with the article, if any, in the classification of races.

Although not explicitly mentioned in the article, we recognized a significant amount of entries that share the same fiscal year ID, sentence ID, and offender ID, and the only difference between these entries are the offence IDs. The assumption to explain this phenomenon is that, when there are multiple offences in one 'crime action', the CSC system had to put multiple entries in to accommodate that, as offence ID and type only records one offence at a time. This assumption should be a plausible explanation since it is common to see crimes that involves break in, robbery, sexual assault, and use of violent force in one crime. After removing all replicated observations, the dataset size is reduced to 142700 entries. In *Section 2.1* and *Section 2.2*, the high degree of similarity in size of the model specific sub-dataset verifies that this action is appropriate. Even though there might be some differences in the details of judging replicated observations, our method should be similar to the actual procedure of the article to some degree.

Figure \@ref(fig:piechart) shows the distribution of race groups among the 20358 entries each representing an unique inmate in early 2016 ('early' since it's collected at end of 15-16 fiscal year). Indigenous inmates account for 23.67% of inmates in our data, this is slightly less than the article's composition of 25.5% Indigenous inmates in early 2016. The Black inmate proportion of 7.94% is slightly less than the article result of 8.7%, and the percentage of inmates other than Black, White, and Indigenous is 8.66%, which is lower than article result of 10.1%. These deviations suggest that, either our approach classify too many inmates as White, or something went different during the data cleaning steps. It is more likely to be the latter case since the White inmates remain untouched through out the race classifications. These differences are expected since the deviation from article results will cumulate throughout the procedure by assuming the specific steps taken to get the article results. By over-classifying more inmates as White, and less in all other race groups, we expect our model estimates to be different, but the significance of the effects should be similar overall.

```{r piechart, fig.cap = "Distribution of race in 2016", echo = FALSE, message = FALSE, out.width="80%"}
rawrep <- RAW%>%filter(`FISCAL YEAR` == "YE1516")
cr <- count(rawrep, RACE)
cr <- cr%>% 
  arrange(desc(RACE))%>%
  mutate(prop = n / sum(cr$n) *100) %>%
  mutate(ypos = cumsum(prop)- 0.5*prop )

par(pty = "s")

pie <- cr%>%ggplot(aes(x= "", y = prop, fill = RACE))+
  geom_bar(stat="identity", width=1, color="white")+
  coord_polar("y", start=0)+
  theme_minimal()+
  theme(axis.text.x=element_blank(), axis.title.x = element_blank(), 
        axis.title.y = element_blank()) +
  geom_text(aes(y = prop/3 + c(0, cumsum(prop)[-length(prop)]), 
            label = percent(prop/100, accuracy = 0.01)))
pie
```

Before introducing the model specific sub-datasets, it is important to check for any empirical results that might suggest any difference between race groups. Figure \@ref(fig:p1) shows the distribution of offender security scores/levels among the four race groups. In case of offender security scores, we are interested in the worst level, which is maximum. It can be seem that Indigenous and Black inmates do have a higher proportion of inmates with maximum security scores, a 5% points more on average than White inmates. Meanwhile, Indigenous and Black inmates have a significant less amount of minimum security scores comparing to White and Other inmates, indicating it is also the case that Indigenous and Black inmates have more medium security scores. 

```{r p1, fig.cap = "Security score distribution among race", echo = FALSE, message = FALSE, out.width="70%"}
nset <- setDT(RAW)[,list(count = .N), by = .(RACE,`OFFENDER SECURITY LEVEL`)][,list(`OFFENDER SECURITY LEVEL` = `OFFENDER SECURITY LEVEL`, count = count, percent_fmt = paste0(formatC(count*100/sum(count), digits = 3), "%"),percent_num = count/sum(count)), by = RACE]
#create percentage distribution of security score among races
nset%>%
  ggplot(aes(x = RACE, 
             #factor to display the levels in order
             y = percent_num,
             fill = factor(`OFFENDER SECURITY LEVEL`,
                           levels = c("MINIMUM",
                                      "MEDIUM",
                                      "MAXIMUM"))))+
  geom_bar(position = position_fill(reverse=FALSE), 
           stat = "identity")+
  #barplot fill with percentage
  coord_flip()+
  geom_text(aes(label = percent_fmt),
            position = position_fill(vjust = 0.5), 
            size = 4,
            check_overlap = TRUE)+
  # turn on check overlap to avoid any overlap
  scale_fill_discrete(name = "Offender Security Level")+
  xlab(label = "Race")+
  ylab(label = "Percentage")
```

Figure \@ref(fig:p2) shows the distribution of reintegration potential score among race groups. The worst level of reintegration score is low, for having the worst potential of reintegrate to the society. Figure \@ref(fig:p2) suggest that Indigenous inmates have 15% point higher proportion of inmates with low reintegration scores than White inmates, and 15% points less with high reintegration score so that the distribution of medium score is similar to White inmates. In general, the distributions of reintegration score are similar between Black inmates and White inmates, suggesting we may not find any evidence that Black inmates are treated different than White inmates when assessing reintegration potential scores.

Note that these are just naive implication of potential racial discrimination when assessing offender security level, and does not represent anything causal before we regress the scores with race, and many other control variables to get closer to a causal link between the two.

```{r p2, fig.cap = "Reintegration score distribution among race", echo = FALSE, message = FALSE, out.width="70%"}
nset2 <- setDT(RAW)[,list(count = .N), by = .(RACE,`REINTEGRATION POTENTIAL`)][,list(`REINTEGRATION POTENTIAL` = `REINTEGRATION POTENTIAL`, count = count, percent_fmt = paste0(formatC(count*100/sum(count), digits = 3), "%"),percent_num = count/sum(count)), by = RACE]
#create percentage distribution of reintegration score among races
nset2%>%
  ggplot(aes(x = RACE, 
             #factor to display the levels in order
             y = percent_num,
             fill = factor(`REINTEGRATION POTENTIAL`,
                           levels = c("LOW",
                                      "MEDIUM",
                                      "HIGH"))))+
  geom_bar(position = position_fill(reverse=FALSE), 
           stat = "identity")+
  #equal length barplot fill with percentage
  coord_flip()+
  geom_text(aes(label = percent_fmt),
            position = position_fill(vjust = 0.5), 
            size = 4,
            check_overlap = TRUE)+
  # turn on check overlap to avoid any overlap
  scale_fill_discrete(name = "Reintegration Potential")+
  xlab(label = "Race")+
  ylab(label = "Percentage")
```

The article 'Bias Behind Bars'[@citebias] tested three models in total, two model assessing impact of race on probability of getting the worst offender security score and reintegration potential score, and one model assessing impact of reintegration score on probability of re-offending. Due to the time constraint of this report and ambiguity in the methodological instructions of the third model, we only replicated the first two models assessing the impact of race on the two assessment scores. For each model, we subset the CSC dataset into sub-datasets since the offender security score assessments are different from reintegration potential scores.

The main issue with the instruction for the third model is how to subset the CSC data. The model should be using the re-offend indicator variable as the response, and using reintegration potential as the predictor along with other controls, and the model itself has no ambiguity. Our understanding of the subset for this model was to generate the re-offend indicator dummy variable for all entries based on if the offender appeared in the dataset for multiple times with unique sentence IDs. However, the article mentioned that, it should have 28110 total entries for this subset. Which makes the whole process ambiguous since there are a lot more than 28110 entries if we are to compare all inmates that re-offended and never re-offended. Since the results using the dataset generated with our understanding are far from the article's result [@citebias], we excluded the third model and it's results.

## Offender Security level Model Subset

As mentioned in the introduction, offender security level is one of the most important score effecting an inmate's life behind bars. It has a set of measure from minimum, medium, to maximum, and maximum bring the 'worst' score. The CSC officer uses an actuarial setting questionnaire called the Custody Rating Scales to measure the security level of an inmate when they first arrive to the designated institution. The questionnaire is focused on the severity of the main offence of current sentence, and any history of drug use or alcohol abuse. Although the security score can be override latter, but the inmate will be transferred to the institution suiting their security level. And maximum level is considered to be the worst score since an inmate with maximum security level will share facility in the same institution with other maximum level inmates, which are likely to be murders or committed other severe crime, and have lower degrees of personal freedom. Meanwhile the low security level inmates will be surrounded by inmates committing fraud or other non-violent crimes, and have more freedom relatively.

Since the offender security level was set when they first arrive, and is not likely to be over-ride in most cases, the dataset for the security score model will only contain the first entry of each inmates with their unique offender ID. We do so by locating the entry of each inmates with the lowest age, and also filtering for inmates that were in custody at the time to eliminate the community service sentences. This is slightly different from the description in the methodology instructions, which was "the dataset looked only at inmates who'd just begun their sentence, since that's when they are assessed with the Custody Rating Scale" [@citemethod]. It is unsure if the article meant to filter for the entries when they just enter, or just filter for all new inmates at the beginning of 2018. 

The response variable of the model is a dummy variable, generated as 1 if the inmate got maximum security level, and 0 otherwise. This generation is required by the logistic regression we introduce in *Section 3*. Lastly, we follow the article to have two sub-models for each score, one for females and one for males, and the sub-dataset will be divided by gender for it.

The sub-dataset using our interpretation leaves 36285 entries, each representing a unique inmate, with 34252 male and 2033 female. While the article suggests a sub-dataset with 22922 entries, with 21439 males and 1483 females. We tried to filter for only new inmates with entries recorded in the fiscal years 2017-2018, but that only leaves 3155 unique entries. Thus, we proceed with the sub-dataset with 34352 entries for the offender security level models, specifically the male security level model and the female security level model.

Instead of checking score distribution for male and female using a bar plot similar to Figure \@ref(fig:p1), we check it using a frequency table. Since the former form does not show count and percentage at the same time, and count does play an important role for smaller dataset like the female dataset. 

Table \@ref(tab:p1m) shows the distribution of security scores for males. The overall distribution is similar to the complete dataset, but it appears that, there are slightly more percentage of maximum security level inmates combined with a lot more percentage of medium security level inmates for both Black and Indigenous inmates. Resulting in approximately 10% points less Black and Indigenous inmates to have minimum security level. However, their gap between the White inmates in term of maximum security level percentage still holds in general.

```{r model1 data, echo = FALSE, message = FALSE}
##this is the specific subset of data for model 1
data1 <- RAW%>%
  group_by(`OFFENDER NUMBER`)%>%
  filter(AGE == min(AGE))
data1 <- data1%>%filter(`IN CUSTODY/COMMUNITY` == "In Custody")
##we assume the inmate's record that are in custody with earliest age is what author mean by "who just begin sentence"
##we have 2 times the article suggested model1 dataset size.
data1$MAXSEC <- ifelse(data1$`OFFENDER SECURITY LEVEL` == "MAXIMUM", 1, 0)
#create dummy for if the offender got the worst security score
colnames(data1)[1] <- "fiscalyear"
colnames(data1)[18] <- "static"
colnames(data1)[11] <- "sentencetype"
colnames(data1)[3] <- "offenderid"
#remove the spaces and special characters for brms function

data1m <- data1%>%filter(GENDER == "MALE")
data1f <- data1%>%filter(GENDER == "FEMALE")
data1r <- data1%>%filter(fiscalyear == "YE1718")
#separate into male and female dataset
```

```{r , echo = FALSE, message = FALSE}
nset3 <- setDT(data1m)[,list(count = .N), by = .(RACE,`OFFENDER SECURITY LEVEL`)][,list(`OFFENDER SECURITY LEVEL` = `OFFENDER SECURITY LEVEL`, count = count, percent_fmt = paste0(formatC(count*100/sum(count), digits = 3), "%"),percent_num = count/sum(count)), by = RACE]
#create percentage distribution of security score among races
```

```{r p1m, echo = FALSE, message = FALSE}
options(knitr.kable.NA = '')
#use knitr to convert NAs into empty strings
kable(nset3[,1:4],
      col.names = c("Race", "Offender Security Level", "Count", "Percentage"),
      align = "c", 
      caption = "Distribution of Security Score for Male")%>%
  kable_styling(latex_options = c("HOLD_position","scale_down"))
```

Table \@ref(tab:p1f) shows the distribution of security scores for females. There are two major difference between the security score female distribution to the complete dataset distribution. Only 3.85% (6 individual) of inmates in Other race groups were assigned with maximum security level, this is significantly lower than the former 8.27%. And only 8% (12 individual) of Black inmates were assigned with maximum security level, again, significantly lower than the former 15.5%. These are the drawbacks of dividing the dataset by gender since the sample size of females in the CSC dataset are naturally less than males. In this case, there are only a total of 150 Black female inmates for the security score model, and it's distribution is not much similar even to the male sub-dataset. Thus, the female security score model can be expected to have different result than the male model, and it may not be statistically significant due to the relatively small sample size under Bayesian settings.

```{r , echo = FALSE, message = FALSE}
nset4 <- setDT(data1f)[,list(count = .N), by = .(RACE,`OFFENDER SECURITY LEVEL`)][,list(`OFFENDER SECURITY LEVEL` = `OFFENDER SECURITY LEVEL`, count = count, percent_fmt = paste0(formatC(count*100/sum(count), digits = 3), "%"),percent_num = count/sum(count)), by = RACE]
#create percentage distribution of security score among races

```

```{r p1f, echo = FALSE, message = FALSE}
options(knitr.kable.NA = '')
#use knitr to convert NAs into empty strings
kable(nset4[,1:4],
      col.names = c("Race", "Offender Security Level", "Count", "Percentage"),
      align = "c", 
      caption = "Distribution of Security Score for Female")%>%
  kable_styling(latex_options = c("HOLD_position","scale_down"))
```

## Reintegration Potential Model Subset

The reintegration potential score is a measure of the inmate's potential ability to re-enter the society after sentence, and the likelihood of not re-offending. Leveling from low, medium, to high, and low is the worst reintegration score indicating a low likelihood of re-enter the society without re-offending. The importance of reintegration potential lie on the parole hearings, a higher reintegration potential helps to gain trust from the parole boards. This score is regularly assessed partially base on Static Factors Assessment, and the other parts depends on the inmate's gender and/or race group. If the inmate is Indigenous or female, the CSC would use the Dynamic Factors Identification and Analysis test, which is a measure of the inmate's life experiences. Otherwise, the CSC uses the Statistical Information on Recidivism scale, which is another measure predicting the likelihood of re-offend. The latter measure was never used on Indigenous or female inmates with intention to prevent cultural bias. Notice that both the Static Factors Assessment and the Dynamic Factors Identification assess the severity of past crime history and life experiences, which are based on the administering officer's subjective judgment and is where the potential issue lies.

Since the reintegration potential scores are assessed each year throughout the sentence, the sub-dataset for reintegration score model will naturally contain more entries since we are allowing multiple entries for each inmate. Since we already eliminated replicated observations, the sub-dataset was defined by simply filtering for all inmates in custody to eliminate all community service status. The resultant dataset contains 91787 entries, 87909 males and 3878 females. Comparing to the article's size of 90524 entries, 86762 males and 3762 females, our dataset is closer to the desired size than previous attempts. Similar to the previous section, the response dummy variable was generated to be 1 for having low reintegration potential, and 0 otherwise. 

```{r model2 data, echo = FALSE, message = FALSE}
#this is the specific subset of data for model 2
data2 <- RAW%>%filter(`IN CUSTODY/COMMUNITY` == "In Custody")
#we have again slightly higher number of observations
data2$LOWINT <- ifelse(data2$`REINTEGRATION POTENTIAL` == "LOW", 1, 0)
#dummy for if the offender got the worst reintegration score
colnames(data2)[1] <- "fiscalyear"
colnames(data2)[18] <- "static"
colnames(data2)[11] <- "sentencetype"
colnames(data2)[3] <- "offenderid"
#remove the spaces and special characters for brms function

data2m <- data2%>%filter(GENDER == "MALE")
data2f <- data2%>%filter(GENDER == "FEMALE")
#separate into male and female dataset
```

Table \@ref(tab:p2m) shows the distribution of reintegration score among males in the model specific dataset. It appears that inmates with high reintegration scores dropped by approximately 10% points on average for all race groups, resulting an increase in the medium and low scores' share. This could be the result of keeping only inmates in custody which may have lower reintegration potential on average, and those excluded inmates in community status may have higher integration potential scores in general. 

```{r , echo = FALSE, message = FALSE}
nset5 <- setDT(data2m)[,list(count = .N), by = .(RACE,`REINTEGRATION POTENTIAL`)][,list(`REINTEGRATION POTENTIAL` = `REINTEGRATION POTENTIAL`, count = count, percent_fmt = paste0(formatC(count*100/sum(count), digits = 3), "%"),percent_num = count/sum(count)), by = RACE]
#create percentage distribution of security score among races
```

```{r p2m, echo = FALSE, message = FALSE}
options(knitr.kable.NA = '')
#use knitr to convert NAs into empty strings
kable(nset5[,1:4],
      col.names = c("Race", "Reintegration Potential", "Count", "Percentage"),
      align = "c", 
      caption = "Distribution of Reintegration Potential for Male")%>%
  kable_styling(latex_options = c("HOLD_position","scale_down"))
```

Table \@ref(tab:p2f) shows the distribution of reintegration score among females in the same dataset. The same pattern of decreasing amount of high reintegration score inmates is observed for White, Indigenous, and Other race groups, but with varying magnitude. White inmates have a reduction of approximately 10% points, 4% points for Indigenous inmates, and 12% points for Other race inmates. However, for Black inmates, a 14% points increase in proportion of high reintegration potential inmates was observed. This could be due to the small sample size of Black female inmate entries, 261 entries among the 3878 entries. Smaller size led to higher variation within the Black female inmates, and thus unusual pattern from the other race groups, and from the Black male inmates.

```{r , echo = FALSE, message = FALSE}
nset6 <- setDT(data2f)[,list(count = .N), by = .(RACE,`REINTEGRATION POTENTIAL`)][,list(`REINTEGRATION POTENTIAL` = `REINTEGRATION POTENTIAL`, count = count, percent_fmt = paste0(formatC(count*100/sum(count), digits = 3), "%"),percent_num = count/sum(count)), by = RACE]
#create percentage distribution of security score among races
```

```{r p2f, echo = FALSE, message = FALSE}
options(knitr.kable.NA = '')
#use knitr to convert NAs into empty strings
kable(nset6[,1:4],
      col.names = c("Race", "Reintegration Potential", "Count", "Percentage"),
      align = "c", 
      caption = "Distribution of Reintegration Potential for Female")%>%
  kable_styling(latex_options = c("HOLD_position","scale_down"))
```

# Model

The models for both scores shares the general form of a binary logistic regression model fitted under Bayesian settings. Binary logistic regression assess the logit probability of an event to occur, in other words, the log likelihood of the dummy response variable to equal to 1. Due to the mathematical property of logistic functions which range from 0 to 1 in the response variables, logistic regression is the natural choice to consider when dealing with binary (dummy) response variables for preventing extrapolation in the predicted response values. As mentioned in the previous sections, we created the dummy response variables to assess the log likelihood of getting the worst offender security score and reintegration potential score using race groups as the main explanatory variable, and including the individual characteristics and other measures from the CSC as control variables. 

The regression models are fitted in `R` [@citeR] using the `brms` package [@citebrms] and `tidybayes` package [@citetidybayes]. The `brms` package is designed for Bayesian regression models, essentially brings the merit of `Stan` using simple `R` syntax and through similar algorithms like Markov chain Monte Carlo (MCMC). MCMC chains allow the model to develop the parameter gradually, and `brms` uses its variant form which is the No-U-Turn Sampler (NUTS) to adapt the samples for posterior distributions, the default 4 chains and 1000 iteration (not including warm-up) were used to fit the model with the help of `brm` function in `brms`. 

The main difference between our Bayesian setting and the article's [@citebias] Frequentist setting is on the interpretation of coefficients, in other words, how we treat the estimates of the effects of being in different race groups. The Frequentist setting interpret the effects as an unknown constant, which is waiting to be estimated by the logistic regression resultant coefficients. The Bayesian setting interpret the effects as random variables, and we estimate the distribution of that random variable using Bayesian logistic regressions. In the Bayesian setting, we can set prior belief about the distribution of those random variables which directly effects the estimated distribution (posterior). In this report, we use the default priors of `brms`, which are t distributions gathered automatically by `brms`, since we do not have much prior belief about the distribution of those effects. The equation for the two models are essentially the same since they include the same explanatory variable and control variables. 

\begin{equation}
Pr(MaxSecurity_{i,t}=1) = logit^{-1}(\beta_{0 }+ \beta_{1}Black_{i,t}+ \beta_{2}Indigenous_{i,t} + \beta_{3}Other_{i,t} + \delta_{1}Age_{i,t} +\sum^{}_{}\alpha_{j}Static_{i,t} + \sum^{}_{}\epsilon_{k} Year_{i,t} + \delta_{2}SentenceType_{i,t}) (\#eq:bayes1)
\end{equation}

\begin{equation}
Pr(LowReint_{i,t}=1) = logit^{-1}(\beta_{0 }+ \beta_{1}Black_{i,t}+ \beta_{2}Indigenous_{i,t} + \beta_{3}Other_{i,t} + \delta_{1}Age_{i,t} +\sum^{}_{}\alpha_{j}Static_{i,t} + \sum^{}_{}\epsilon_{k} Year_{i,t} + \delta_{2}SentenceType_{i,t}) (\#eq:bayes2)
\end{equation}

Equation \@ref(eq:bayes1) and equation \@ref(eq:bayes2) displays the equations for the two binary logistic regression models. However, remember that each model will be fitted twice, one time for male inmates only and one time for female inmates only, each based on the corresponding sub-dataset discussed in *Section 2*. Race is the main explanatory variable we are interested in, since we are trying to replicate the results of 'Bias Behind Bars' [@citebias]. Three dummy variables were set up so that they equal to 1 if the inmate is Indigenous, Black, or Other race respectively, and if one of these dummy equals to 1, the other two equals to 0 automatically. White is manually set as the reference group, meaning it's effect is integrated into the intercept ($\beta_{0}$). Due to this dummy variable coding format, the interpretation of the $\beta_{1,2,3}$ is the average percent difference in the likelihood of getting the worst scores for being Indigenous, Black, or Other race alone, holding all other control variables constant.

Beside the race groups being the main interest the article and of this report, these choices of control variables are based on the methodology instructions [@citemethod], but with exclusion of the variable representing weight of the most severe offence of an inmate. As mentioned in the previous sections, the control variables include age, static score, year, and sentence type. Age is a numeric variable, and interpretation of $\delta_{1}$ is the average increase in likelihood of getting the worst scores for each additional increase in age, holding all other explanatory variables constant. Static score is a categorical variable, as discussed in *Section 2*, it levels from low, medium, to high. The `brms` automatically create dummy variables for categorical variables in a similar format as we did for race groups. However, we did not manually set a specific reference groups so `brms` will pick the reference group automatically, which may be different across models. The $\alpha_{j}$s are the two coefficients for the two non-reference dummy variables, with interpretation similar to the $\beta$s.

Year is also a categorical variable representing the fiscal year of the entry, by automatically creating the dummy variables, adding year is essentially adding year fixed effects into the model. However, the article did not add individual fixed effects and the possible individual specific time trends which are some useful controls to look into. The reason was not discussed in the article and the methodology instructions, thus, we did not add the individual fixed effects for replication purpose. The $\epsilon_{k}$s are the six coefficients for the six non-reference dummy variables, with interpretation similar to the $\beta$s. Sentence type is a categorical variable with only two levels, determinate or indeterminate), so `brms` will only create one dummy for it. Thus, $\delta_{2}$ is interpreted as the average difference in likelihood of getting the worst score between the reference and non-reference sentence types, holding all other explanatory variables constant. 

Figure \@ref(fig:trace) in the appendix displays the trace plots of the parameters during the MCMC chains of all four fitted models, these plots were created in `R` [@citer] using functions in `brms` [@citebrms] package. An ideal trace plot would be in a consistent and rapid up-and-down shape with no long term trend. All of the trace plots appear to satisfy that requirement, and there is no divergent transitions during the MCMC chains which would be indicated in red by `brms` if any. These findings show evidence that our fitted model is not fractured, and the reliability of these fitted models are assessed in the next section, *Section 4*.

```{r model1, echo = FALSE, message = FALSE}
model1m <- brm(MAXSEC ~ relevel(factor(RACE), ref = "White") + AGE + static + fiscalyear + sentencetype, 
            data = data1m, 
            family = bernoulli(),
            seed = 6431,
            #seed not perfect in brm, but better than nothing
            silent = TRUE,
            refresh = 0,
            #the above option turns off all message completely wen knitting
            file = "/Users/jordans2000/Desktop/STA304/Replicate-Bias-Behind-Bars/outputs/model/model1m")
model1f <- brm(MAXSEC ~ relevel(factor(RACE), ref = "White") + AGE + static + fiscalyear + sentencetype, 
            data = data1f, 
            family = bernoulli(),
            seed = 6431,
            #seed not perfect in brm, but better than nothing
            silent = TRUE,
            refresh = 0,
            #the above option turns off all message completely wen knitting
            file = "/Users/jordans2000/Desktop/STA304/Replicate-Bias-Behind-Bars/outputs/model/model1f")
```

```{r model2, echo = FALSE, MESSAGE = FALSE}
model2m <- brm(LOWINT ~ relevel(factor(RACE), ref = "White") + AGE + static + fiscalyear + sentencetype, 
            data = data2m, 
            family = bernoulli(),
            seed = 6431,
            #seed not perfect in brm, but better than nothing
            silent = TRUE,
            refresh = 0,
            #the above option turns off all message completely wen knitting
            file = "/Users/jordans2000/Desktop/STA304/Replicate-Bias-Behind-Bars/outputs/model/model2m")

model2f <- brm(LOWINT ~ relevel(factor(RACE), ref = "White") + AGE + static + fiscalyear + sentencetype, 
            data = data2f, 
            family = bernoulli(),
            seed = 6431,
            #seed not perfect in brm, but better than nothing
            silent = TRUE,
            refresh = 0,
            #the above option turns off all message completely wen knitting
            file = "/Users/jordans2000/Desktop/STA304/Replicate-Bias-Behind-Bars/outputs/model/model2f")

```


# Results

## Security Socre Model

```{r}

```


## Reintegration Score Model

```{r}

```


# Discussion and Conclusion

\newpage

# Appendix {-}

```{r trace, fig.cap = "Trace plots of all model", echo = FALSE, message = FALSE, out.width="50%"}
mcmc_plot(model1m, type = "trace")

mcmc_plot(model1f, type = "trace")

mcmc_plot(model2m, type = "trace")

mcmc_plot(model2f, type = "trace")
#no divergence during the chains in all models
```

\newpage

# References
